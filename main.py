import time
import csv
import os
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException

from scrape_dm_cards import (
    create_driver,
    parse_card_detail,
    load_existing_names,
    CSV_FILE,
    BASE_DOMAIN
)

# =========================
# è¨­å®š
# =========================
SLEEP_SEC = 3  # ãƒšãƒ¼ã‚¸é–“ã®å¾…æ©Ÿæ™‚é–“ã‚’å¢—ã‚„ã™
RESTART_INTERVAL = 10
MAX_RETRY_GET = 3
MAX_RETRY_STALE = 3  # Staleè¦ç´ ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°


# =========================
# ãƒšãƒ¼ã‚¸URLç”Ÿæˆï¼ˆURLç›´æ‰“ã¡æ–¹å¼ï¼‰
# =========================
def build_page_url(page_num: int) -> str:
    return (
        "https://dm.takaratomy.co.jp/card/"
        "?v=%7B"
        "%22suggest%22:%22on%22,"
        "%22keyword_type%22:%5B%22card_name%22,%22card_ruby%22,%22card_text%22%5D,"
        "%22culture_cond%22:%5B%22%E5%8D%98%E8%89%B2%22,%22%E5%A4%9A%E8%89%B2%22%5D,"
        f"%22pagenum%22:%22{page_num}%22,"
        "%22samename%22:%22show%22,"
        "%22sort%22:%22release_new%22"
        "%7D"
    )


# =========================
# å®‰å…¨ãª driver.get
# =========================
def safe_get(driver, wait, url):
    for i in range(MAX_RETRY_GET):
        try:
            driver.get(url)
            time.sleep(2)  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾Œã®è¿½åŠ å¾…æ©Ÿ
            wait.until(
                EC.presence_of_all_elements_located(
                    (By.CLASS_NAME, "cardImage")
                )
            )
            time.sleep(1)  # DOMå®‰å®šåŒ–ã®ãŸã‚ã®è¿½åŠ å¾…æ©Ÿ
            return True
        except Exception as e:
            print(f"driver.get å†è©¦è¡Œ {i+1}/{MAX_RETRY_GET}: {e}")
            time.sleep(3)
    return False


# =========================
# data-hrefæŠ½å‡ºï¼ˆStaleå¯¾ç­–ä»˜ãï¼‰
# =========================
def extract_card_urls(driver):
    """ã‚«ãƒ¼ãƒ‰ã®URLã‚’å®‰å…¨ã«æŠ½å‡ºã™ã‚‹"""
    for attempt in range(MAX_RETRY_STALE):
        try:
            # æ¯å›æ–°ã—ãè¦ç´ ã‚’å–å¾—
            cards = driver.find_elements(By.CLASS_NAME, "cardImage")
            
            if not cards:
                return []
            
            # JavaScriptã§ä¸€æ°—ã«å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆStaleå®Œå…¨å›é¿ï¼‰
            detail_urls = driver.execute_script("""
                var cards = document.getElementsByClassName('cardImage');
                var urls = [];
                for (var i = 0; i < cards.length; i++) {
                    var href = cards[i].getAttribute('data-href');
                    if (href) {
                        urls.push(href);
                    }
                }
                return urls;
            """)
            
            # ãƒ™ãƒ¼ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è¿½åŠ 
            full_urls = [BASE_DOMAIN + url for url in detail_urls if url]
            return full_urls
            
        except StaleElementReferenceException as e:
            print(f"Staleè¦ç´ ã‚¨ãƒ©ãƒ¼ å†è©¦è¡Œ {attempt+1}/{MAX_RETRY_STALE}")
            time.sleep(2)
        except Exception as e:
            print(f"URLæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            time.sleep(2)
    
    return []


# =========================
# ãƒšãƒ¼ã‚¸æ¤œè¨¼ï¼ˆ1ãƒšãƒ¼ã‚¸ç›®ã«æˆ»ã£ã¦ã„ãªã„ã‹ç¢ºèªï¼‰
# =========================
def verify_page_content(driver, expected_page):
    """ç¾åœ¨ã®ãƒšãƒ¼ã‚¸ãŒæœŸå¾…ã™ã‚‹ãƒšãƒ¼ã‚¸ã‹ã‚’æ¤œè¨¼"""
    try:
        # ãƒšãƒ¼ã‚¸ç•ªå·è¦ç´ ã‚’æ¢ã™ï¼ˆã‚µã‚¤ãƒˆã®ä»•æ§˜ã«å¿œã˜ã¦èª¿æ•´ãŒå¿…è¦ï¼‰
        time.sleep(1)
        current_url = driver.current_url
        
        # URLã«ãƒšãƒ¼ã‚¸ç•ªå·ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        if f'pagenum%22:%22{expected_page}%22' in current_url:
            return True
        
        print(f"âš ï¸  è­¦å‘Š: ãƒšãƒ¼ã‚¸ {expected_page} ã‚’æœŸå¾…ã—ã¦ã„ã¾ã—ãŸãŒã€URLãŒä¸€è‡´ã—ã¾ã›ã‚“")
        print(f"   ç¾åœ¨ã®URL: {current_url}")
        return False
        
    except Exception as e:
        print(f"ãƒšãƒ¼ã‚¸æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return True  # æ¤œè¨¼ã§ããªã„å ´åˆã¯ç¶šè¡Œ


# =========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================
def main(start_page=1, end_page=None):
    driver = create_driver()
    wait = WebDriverWait(driver, 20)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·

    existing_names = load_existing_names()
    file_exists = os.path.exists(CSV_FILE)
    
    consecutive_empty_pages = 0  # é€£ç¶šç©ºãƒšãƒ¼ã‚¸ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
    MAX_EMPTY_PAGES = 3  # 3ãƒšãƒ¼ã‚¸é€£ç¶šã§ç©ºãªã‚‰çµ‚äº†

    try:
        with open(CSV_FILE, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(
                f,
                fieldnames=[
                    "card_name",
                    "civilization",
                    "color_type",
                    "card_type",
                    "cost",
                    "power",
                    "race",
                    "text",
                    "tags"
                ]
            )

            if not file_exists:
                writer.writeheader()

            page = start_page
            while True:
                if end_page is not None and page > end_page:
                    print("\n=== end_page ã«åˆ°é” ===")
                    break

                # Chrome å®šæœŸå†èµ·å‹•
                if (page - start_page) % RESTART_INTERVAL == 0 and page != start_page:
                    print("\n=== Chrome å†èµ·å‹• ===")
                    driver.quit()
                    time.sleep(3)
                    driver = create_driver()
                    wait = WebDriverWait(driver, 20)

                print(f"\n=== Page {page} ===")
                url = build_page_url(page)
                #print(f"URL: {url}")

                if not safe_get(driver, wait, url):
                    print("âŒ ãƒšãƒ¼ã‚¸å–å¾—å¤±æ•—ã€‚çµ‚äº†")
                    break

                # ãƒšãƒ¼ã‚¸å†…å®¹ã‚’æ¤œè¨¼
                verify_page_content(driver, page)

                # data-href ã‚’å®‰å…¨ã«æŠ½å‡º
                detail_urls = extract_card_urls(driver)
                
                print(f"å–å¾—ã‚«ãƒ¼ãƒ‰æ•°: {len(detail_urls)}")

                if not detail_urls:
                    consecutive_empty_pages += 1
                    print(f"âš ï¸  ã‚«ãƒ¼ãƒ‰ãªã—ï¼ˆé€£ç¶š {consecutive_empty_pages}/{MAX_EMPTY_PAGES}ï¼‰")
                    
                    if consecutive_empty_pages >= MAX_EMPTY_PAGES:
                        print("âŒ é€£ç¶šç©ºãƒšãƒ¼ã‚¸ä¸Šé™ã«åˆ°é”ã€‚çµ‚äº†")
                        break
                    
                    page += 1
                    time.sleep(SLEEP_SEC)
                    continue
                else:
                    consecutive_empty_pages = 0  # ãƒªã‚»ãƒƒãƒˆ

                # å„ã‚«ãƒ¼ãƒ‰ã®è©³ç´°ã‚’å–å¾—
                new_cards_count = 0
                for idx, detail_url in enumerate(detail_urls, 1):
                    print(f"  [{idx}/{len(detail_urls)}] å‡¦ç†ä¸­...")
                    
                    card_data = parse_card_detail(detail_url)
                    if not card_data:
                        continue

                    name = card_data["card_name"]
                    if not name or name in existing_names:
                        print(f"  ã‚¹ã‚­ãƒƒãƒ—: {name}")
                        continue

                    writer.writerow(card_data)
                    f.flush()  # å³åº§ã«ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
                    existing_names.add(name)
                    new_cards_count += 1
                    print(f"  âœ… è¿½åŠ : {name}")

                print(f"ğŸ“Š ãƒšãƒ¼ã‚¸ {page} å®Œäº†: {new_cards_count}æšã®æ–°è¦ã‚«ãƒ¼ãƒ‰ã‚’è¿½åŠ ")
                
                page += 1
                time.sleep(SLEEP_SEC)

        print("\nğŸ‰ === å…¨ã‚«ãƒ¼ãƒ‰å–å¾—å®Œäº† ===")

    except KeyboardInterrupt:
        print("\nâš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­") #ctrl+cã§å¼·åˆ¶çµ‚äº†å¯èƒ½
    except Exception as e:
        print(f"\nâŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    finally:
        driver.quit()
        print(f"\næœ€çµ‚å‡¦ç†ãƒšãƒ¼ã‚¸: {page-1}")


if __name__ == "__main__":
    main(start_page=247, end_page=423)